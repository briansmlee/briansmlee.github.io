---
layout: page
title: 3.2 Linear Regression Models and Least Squares
permalink: /esl/chapter_3_1/
usemathjax: true
---

# Covariance matrix of least squares parameter estimate (3.8)
![Derive (3.8)](/assets/esl/3.8.jpg)

Reference: [EdX ColumbiaX Machine Learning](https://www.edx.org/course/machine-learning), Lecture 3.

# Estimate $$\hat{\sigma}^2$$ of $$y_i$$'s variance $$\sigma^2$$ is unbiased (3.8)

See [this Math StackExchange answer](https://math.stackexchange.com/a/2342977/455856). Note that this answer assumes that the variance $$\sigma^2$$ of $$y_i$$ comes from $$\varepsilon \sim N(0, \sigma^2)$$.

TODO: Is it possible to derive without the assumption above?

# Under (3.9), least squares parameter estimate is normal (3.10)

![Derive (3.10)](/assets/esl/3.10.jpg)

# Variance estimate has chi-squared distribution with $$N-p-1$$ (3.11)

See [this Math StackExchange answer](https://stats.stackexchange.com/a/20230/261782). Below slightly extends the answer by using a bit easier (imo) linear algebra.

![Derive (3.11)](/assets/esl/3.11.jpg)